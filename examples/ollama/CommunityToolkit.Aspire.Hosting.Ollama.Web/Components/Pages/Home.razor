@page "/"
@using Microsoft.Extensions.AI
@rendermode InteractiveServer

<PageTitle>Home</PageTitle>

<h1>Ollama demo</h1>

<p>Welcome to the Ollama demo!</p>

<fieldset>
    <legend>Model</legend>
    <InputRadioGroup @bind-Value="_selectedClient">
        <div>
            <label>
                <InputRadio Value="ServiceKeys.Phi3" />
                @(OllamaClient1.GetService<ChatClientMetadata>()?.DefaultModelId)
            </label>
        </div>
        <div>
            <label>
                <InputRadio Value="ServiceKeys.Llama" />
                @(OllamaClient2.GetService<ChatClientMetadata>()?.DefaultModelId)
            </label>
        </div>
    </InputRadioGroup>
</fieldset>

<p><input type="text" @bind-value="_prompt" />&nbsp;<button @onclick="GetPrompt">Ask</button></p>
<p>@_response</p>

@code {
    private string _prompt = "";
    private string _response = "";

    private string? _selectedClient;

    [Inject(Key = ServiceKeys.Phi3)]
    public required IChatClient OllamaClient1 { get; set; }

    [Inject(Key = ServiceKeys.Llama)]
    public required IChatClient OllamaClient2 { get; set; }

    private async Task GetPrompt()
    {
        var client = _selectedClient switch
        {
            ServiceKeys.Phi3 => OllamaClient1,
            ServiceKeys.Llama => OllamaClient2,
            _ => null
        };

        if (!string.IsNullOrWhiteSpace(_prompt))
        {
            if (client is null)
            {
                _response = "No model selected";
                return;
            }

            bool gotResponse = false;
            _response = "Asking Ollama...";

            var stream = client.GetStreamingResponseAsync(_prompt);

            await foreach (var answerToken in stream)
            {
                if (!gotResponse)
                {
                    _response = "";
                    gotResponse = true;
                }

                _response += answerToken.Text;
                StateHasChanged();
            }
        }
    }
}
